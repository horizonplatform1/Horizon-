"""
Advanced Real-Time Tracking and Monitoring System
Provides comprehensive real-time monitoring of blockchain, market, and governance activities
with intelligent alerting and automated response capabilities
"""

import asyncio
import websockets
import json
import logging
import threading
import time
import queue
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Callable, Any
import sqlite3
import pandas as pd
import numpy as np
from dataclasses import dataclass, asdict
import yfinance as yf
import requests
from concurrent.futures import ThreadPoolExecutor
import os

from blockchain.core import Blockchain, Transaction


@dataclass
class RealTimeEvent:
    """Represents a real-time event"""
    event_id: str
    event_type: str
    source: str
    timestamp: datetime
    data: Dict[str, Any]
    severity: str  # 'LOW', 'MEDIUM', 'HIGH', 'CRITICAL'
    processed: bool = False


@dataclass
class Alert:
    """Represents an alert generated by the monitoring system"""
    alert_id: str
    alert_type: str
    title: str
    message: str
    severity: str
    timestamp: datetime
    source_event: str
    actions_taken: List[str] = None
    resolved: bool = False


@dataclass
class MonitoringRule:
    """Represents a monitoring rule"""
    rule_id: str
    rule_name: str
    rule_type: str  # 'threshold', 'pattern', 'anomaly'
    conditions: Dict[str, Any]
    actions: List[str]
    enabled: bool = True
    cooldown_period: int = 300  # seconds


class MarketDataStreamer:
    """Real-time market data streaming"""
    
    def __init__(self):
        self.companies = ['GOOGL', 'MSFT', 'CMCSA']
        self.streaming = False
        self.data_queue = queue.Queue()
        self.websocket_connections = {}
        
    def start_streaming(self):
        """Start real-time market data streaming"""
        self.streaming = True
        
        def stream_data():
            while self.streaming:
                try:
                    for company in self.companies:
                        # Simulate real-time data (in practice, would use real WebSocket APIs)
                        market_data = self._fetch_current_data(company)
                        
                        if market_data:
                            event = RealTimeEvent(
                                event_id=f"market_{company}_{int(time.time())}",
                                event_type='market_update',
                                source=f'market_data_{company}',
                                timestamp=datetime.now(),
                                data=market_data,
                                severity='LOW'
                            )
                            self.data_queue.put(event)
                    
                    time.sleep(30)  # Update every 30 seconds
                    
                except Exception as e:
                    logging.error(f"Error in market data streaming: {e}")
                    time.sleep(60)
        
        threading.Thread(target=stream_data, daemon=True).start()
        logging.info("Market data streaming started")
    
    def stop_streaming(self):
        """Stop market data streaming"""
        self.streaming = False
        logging.info("Market data streaming stopped")
    
    def _fetch_current_data(self, symbol: str) -> Dict[str, Any]:
        """Fetch current market data for a symbol"""
        try:
            ticker = yf.Ticker(symbol)
            data = ticker.history(period="1d", interval="1m")
            
            if not data.empty:
                latest = data.iloc[-1]
                previous = data.iloc[-2] if len(data) > 1 else latest
                
                return {
                    'symbol': symbol,
                    'price': float(latest['Close']),
                    'volume': int(latest['Volume']),
                    'high': float(latest['High']),
                    'low': float(latest['Low']),
                    'change': float(latest['Close'] - previous['Close']),
                    'change_percent': float((latest['Close'] - previous['Close']) / previous['Close'] * 100),
                    'timestamp': latest.name.isoformat()
                }
        except Exception as e:
            logging.error(f"Error fetching data for {symbol}: {e}")
            return {}


class BlockchainMonitor:
    """Real-time blockchain monitoring"""
    
    def __init__(self, blockchain: Blockchain):
        self.blockchain = blockchain
        self.monitoring = False
        self.last_block_count = 0
        self.event_queue = queue.Queue()
        
    def start_monitoring(self):
        """Start blockchain monitoring"""
        self.monitoring = True
        self.last_block_count = len(self.blockchain.chain)
        
        def monitor_blockchain():
            while self.monitoring:
                try:
                    current_block_count = len(self.blockchain.chain)
                    
                    # Check for new blocks
                    if current_block_count > self.last_block_count:
                        for i in range(self.last_block_count, current_block_count):
                            if i < len(self.blockchain.chain):
                                block = self.blockchain.chain[i]
                                self._process_new_block(block)
                        
                        self.last_block_count = current_block_count
                    
                    # Monitor transaction pool
                    pending_tx_count = len(getattr(self.blockchain, 'pending_transactions', []))
                    if pending_tx_count > 10:  # Alert on high pending transactions
                        event = RealTimeEvent(
                            event_id=f"blockchain_congestion_{int(time.time())}",
                            event_type='blockchain_congestion',
                            source='blockchain_monitor',
                            timestamp=datetime.now(),
                            data={'pending_transactions': pending_tx_count},
                            severity='MEDIUM'
                        )
                        self.event_queue.put(event)
                    
                    time.sleep(10)  # Check every 10 seconds
                    
                except Exception as e:
                    logging.error(f"Error in blockchain monitoring: {e}")
                    time.sleep(30)
        
        threading.Thread(target=monitor_blockchain, daemon=True).start()
        logging.info("Blockchain monitoring started")
    
    def stop_monitoring(self):
        """Stop blockchain monitoring"""
        self.monitoring = False
        logging.info("Blockchain monitoring stopped")
    
    def _process_new_block(self, block):
        """Process a new block and generate events"""
        try:
            # Analyze block for significant transactions
            for transaction in block.transactions:
                if self._is_significant_transaction(transaction):
                    event = RealTimeEvent(
                        event_id=f"significant_tx_{transaction.transaction_id}",
                        event_type='significant_transaction',
                        source='blockchain_monitor',
                        timestamp=datetime.now(),
                        data={
                            'transaction_id': transaction.transaction_id,
                            'transaction_type': transaction.transaction_type,
                            'amount': getattr(transaction, 'amount', 0),
                            'from_address': transaction.from_address,
                            'to_address': transaction.to_address
                        },
                        severity='HIGH'
                    )
                    self.event_queue.put(event)
            
            # General new block event
            event = RealTimeEvent(
                event_id=f"new_block_{block.block_hash}",
                event_type='new_block',
                source='blockchain_monitor',
                timestamp=datetime.now(),
                data={
                    'block_index': block.index,
                    'block_hash': block.block_hash,
                    'transaction_count': len(block.transactions),
                    'miner': block.miner
                },
                severity='LOW'
            )
            self.event_queue.put(event)
            
        except Exception as e:
            logging.error(f"Error processing new block: {e}")
    
    def _is_significant_transaction(self, transaction) -> bool:
        """Determine if a transaction is significant"""
        try:
            # Check for large share purchases
            if transaction.transaction_type == 'share_purchase':
                amount = getattr(transaction, 'amount', 0)
                return amount > 1000000  # $1M threshold
            
            # Check for governance-related transactions
            if transaction.transaction_type in ['governance_vote', 'board_proposal']:
                return True
                
            return False
        except:
            return False


class GovernanceMonitor:
    """Real-time governance activity monitoring"""
    
    def __init__(self):
        self.monitoring = False
        self.event_queue = queue.Queue()
        
    def start_monitoring(self):
        """Start governance monitoring"""
        self.monitoring = True
        
        def monitor_governance():
            while self.monitoring:
                try:
                    # Monitor SEC filings (simulated)
                    self._check_sec_filings()
                    
                    # Monitor news for governance-related activities
                    self._check_governance_news()
                    
                    # Monitor social media sentiment
                    self._check_social_sentiment()
                    
                    time.sleep(300)  # Check every 5 minutes
                    
                except Exception as e:
                    logging.error(f"Error in governance monitoring: {e}")
                    time.sleep(60)
        
        threading.Thread(target=monitor_governance, daemon=True).start()
        logging.info("Governance monitoring started")
    
    def stop_monitoring(self):
        """Stop governance monitoring"""
        self.monitoring = False
        logging.info("Governance monitoring stopped")
    
    def _check_sec_filings(self):
        """Check for new SEC filings"""
        try:
            # Simulate SEC filing monitoring
            for company in ['GOOGL', 'MSFT', 'CMCSA']:
                # In practice, would query SEC EDGAR database
                if np.random.random() < 0.01:  # 1% chance of new filing
                    event = RealTimeEvent(
                        event_id=f"sec_filing_{company}_{int(time.time())}",
                        event_type='sec_filing',
                        source='sec_monitor',
                        timestamp=datetime.now(),
                        data={
                            'company': company,
                            'filing_type': np.random.choice(['10-K', '10-Q', '8-K', 'DEF 14A']),
                            'description': 'New SEC filing detected'
                        },
                        severity='MEDIUM'
                    )
                    self.event_queue.put(event)
        except Exception as e:
            logging.error(f"Error checking SEC filings: {e}")
    
    def _check_governance_news(self):
        """Check for governance-related news"""
        try:
            # Simulate news monitoring
            governance_keywords = ['merger', 'acquisition', 'board', 'proxy', 'shareholder', 'takeover']
            
            for company in ['GOOGL', 'MSFT', 'CMCSA']:
                if np.random.random() < 0.05:  # 5% chance of relevant news
                    keyword = np.random.choice(governance_keywords)
                    event = RealTimeEvent(
                        event_id=f"governance_news_{company}_{int(time.time())}",
                        event_type='governance_news',
                        source='news_monitor',
                        timestamp=datetime.now(),
                        data={
                            'company': company,
                            'keyword': keyword,
                            'headline': f"{company} {keyword} activity detected",
                            'sentiment': np.random.uniform(-0.5, 0.5)
                        },
                        severity='MEDIUM'
                    )
                    self.event_queue.put(event)
        except Exception as e:
            logging.error(f"Error checking governance news: {e}")
    
    def _check_social_sentiment(self):
        """Check social media sentiment"""
        try:
            # Simulate social sentiment monitoring
            for company in ['GOOGL', 'MSFT', 'CMCSA']:
                sentiment = np.random.normal(0, 0.3)
                
                if abs(sentiment) > 0.5:  # Extreme sentiment
                    severity = 'HIGH' if abs(sentiment) > 0.7 else 'MEDIUM'
                    event = RealTimeEvent(
                        event_id=f"sentiment_{company}_{int(time.time())}",
                        event_type='sentiment_alert',
                        source='social_monitor',
                        timestamp=datetime.now(),
                        data={
                            'company': company,
                            'sentiment_score': sentiment,
                            'sentiment_type': 'positive' if sentiment > 0 else 'negative'
                        },
                        severity=severity
                    )
                    self.event_queue.put(event)
        except Exception as e:
            logging.error(f"Error checking social sentiment: {e}")


class RuleEngine:
    """Rule engine for processing events and generating alerts"""
    
    def __init__(self):
        self.rules = []
        self.alert_history = {}
        self._load_default_rules()
        
    def _load_default_rules(self):
        """Load default monitoring rules"""
        default_rules = [
            MonitoringRule(
                rule_id='price_spike',
                rule_name='Price Spike Detection',
                rule_type='threshold',
                conditions={'change_percent_abs': 5.0},
                actions=['send_alert', 'log_event']
            ),
            MonitoringRule(
                rule_id='volume_spike',
                rule_name='Volume Spike Detection',
                rule_type='threshold',
                conditions={'volume_multiplier': 3.0},
                actions=['send_alert', 'analyze_cause']
            ),
            MonitoringRule(
                rule_id='governance_event',
                rule_name='Governance Event Detection',
                rule_type='pattern',
                conditions={'event_type': ['sec_filing', 'governance_news']},
                actions=['send_alert', 'notify_board', 'log_event']
            ),
            MonitoringRule(
                rule_id='large_transaction',
                rule_name='Large Transaction Detection',
                rule_type='threshold',
                conditions={'transaction_amount': 1000000},
                actions=['send_alert', 'verify_compliance', 'log_event']
            )
        ]
        
        self.rules.extend(default_rules)
    
    def process_event(self, event: RealTimeEvent) -> List[Alert]:
        """Process an event against all rules"""
        alerts = []
        
        for rule in self.rules:
            if not rule.enabled:
                continue
                
            # Check cooldown
            if self._is_in_cooldown(rule.rule_id, event.event_type):
                continue
            
            # Evaluate rule conditions
            if self._evaluate_rule(rule, event):
                alert = self._generate_alert(rule, event)
                alerts.append(alert)
                
                # Execute rule actions
                self._execute_actions(rule.actions, event, alert)
                
                # Update cooldown
                self._update_cooldown(rule.rule_id, event.event_type)
        
        return alerts
    
    def _evaluate_rule(self, rule: MonitoringRule, event: RealTimeEvent) -> bool:
        """Evaluate if an event matches a rule"""
        try:
            if rule.rule_type == 'threshold':
                return self._evaluate_threshold_rule(rule, event)
            elif rule.rule_type == 'pattern':
                return self._evaluate_pattern_rule(rule, event)
            elif rule.rule_type == 'anomaly':
                return self._evaluate_anomaly_rule(rule, event)
            return False
        except Exception as e:
            logging.error(f"Error evaluating rule {rule.rule_id}: {e}")
            return False
    
    def _evaluate_threshold_rule(self, rule: MonitoringRule, event: RealTimeEvent) -> bool:
        """Evaluate threshold-based rule"""
        conditions = rule.conditions
        data = event.data
        
        for condition, threshold in conditions.items():
            if condition == 'change_percent_abs':
                change_pct = abs(data.get('change_percent', 0))
                if change_pct >= threshold:
                    return True
            elif condition == 'volume_multiplier':
                # Would need historical volume data for comparison
                return False  # Placeholder
            elif condition == 'transaction_amount':
                amount = data.get('amount', 0)
                if amount >= threshold:
                    return True
        
        return False
    
    def _evaluate_pattern_rule(self, rule: MonitoringRule, event: RealTimeEvent) -> bool:
        """Evaluate pattern-based rule"""
        conditions = rule.conditions
        
        if 'event_type' in conditions:
            allowed_types = conditions['event_type']
            if isinstance(allowed_types, list):
                return event.event_type in allowed_types
            else:
                return event.event_type == allowed_types
        
        return False
    
    def _evaluate_anomaly_rule(self, rule: MonitoringRule, event: RealTimeEvent) -> bool:
        """Evaluate anomaly-based rule"""
        # Placeholder for anomaly detection logic
        return False
    
    def _generate_alert(self, rule: MonitoringRule, event: RealTimeEvent) -> Alert:
        """Generate an alert from a rule and event"""
        alert_id = f"alert_{rule.rule_id}_{int(time.time())}"
        
        # Determine severity
        severity = event.severity
        if rule.rule_id in ['large_transaction', 'governance_event']:
            severity = 'HIGH'
        
        # Generate message
        message = f"Rule '{rule.rule_name}' triggered by event {event.event_type}"
        title = f"{rule.rule_name} Alert"
        
        if event.event_type == 'market_update':
            symbol = event.data.get('symbol', '')
            change = event.data.get('change_percent', 0)
            message = f"Significant price movement detected for {symbol}: {change:.2f}%"
            title = f"Price Alert - {symbol}"
        
        return Alert(
            alert_id=alert_id,
            alert_type=rule.rule_id,
            title=title,
            message=message,
            severity=severity,
            timestamp=datetime.now(),
            source_event=event.event_id,
            actions_taken=[],
            resolved=False
        )
    
    def _execute_actions(self, actions: List[str], event: RealTimeEvent, alert: Alert):
        """Execute actions for a triggered rule"""
        for action in actions:
            try:
                if action == 'send_alert':
                    self._send_alert_notification(alert)
                elif action == 'log_event':
                    self._log_event(event, alert)
                elif action == 'notify_board':
                    self._notify_board(event, alert)
                elif action == 'verify_compliance':
                    self._verify_compliance(event, alert)
            except Exception as e:
                logging.error(f"Error executing action {action}: {e}")
    
    def _send_alert_notification(self, alert: Alert):
        """Send alert notification"""
        logging.warning(f"ALERT: {alert.title} - {alert.message}")
        # In practice, would send via email, SMS, webhook, etc.
    
    def _log_event(self, event: RealTimeEvent, alert: Alert):
        """Log event and alert"""
        logging.info(f"Event logged: {event.event_type} triggered alert {alert.alert_type}")
    
    def _notify_board(self, event: RealTimeEvent, alert: Alert):
        """Notify board members"""
        logging.info(f"Board notification sent for event: {event.event_type}")
    
    def _verify_compliance(self, event: RealTimeEvent, alert: Alert):
        """Verify compliance requirements"""
        logging.info(f"Compliance verification initiated for event: {event.event_type}")
    
    def _is_in_cooldown(self, rule_id: str, event_type: str) -> bool:
        """Check if rule is in cooldown period"""
        key = f"{rule_id}_{event_type}"
        if key in self.alert_history:
            last_alert = self.alert_history[key]
            return (datetime.now() - last_alert).seconds < 300  # 5 minute cooldown
        return False
    
    def _update_cooldown(self, rule_id: str, event_type: str):
        """Update cooldown timestamp"""
        key = f"{rule_id}_{event_type}"
        self.alert_history[key] = datetime.now()


class AdvancedRealTimeTracker:
    """Main advanced real-time tracking system"""
    
    def __init__(self, blockchain: Blockchain):
        self.blockchain = blockchain
        self.market_streamer = MarketDataStreamer()
        self.blockchain_monitor = BlockchainMonitor(blockchain)
        self.governance_monitor = GovernanceMonitor()
        self.rule_engine = RuleEngine()
        
        self.tracking_active = False
        self.event_processor_active = False
        self.db_path = "data/real_time_tracking.db"
        
        self._init_database()
        
    def _init_database(self):
        """Initialize tracking database"""
        os.makedirs("data", exist_ok=True)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Events table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS events (
                event_id TEXT PRIMARY KEY,
                event_type TEXT NOT NULL,
                source TEXT NOT NULL,
                timestamp DATETIME NOT NULL,
                data TEXT NOT NULL,
                severity TEXT NOT NULL,
                processed BOOLEAN DEFAULT FALSE
            )
        ''')
        
        # Alerts table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS alerts (
                alert_id TEXT PRIMARY KEY,
                alert_type TEXT NOT NULL,
                title TEXT NOT NULL,
                message TEXT NOT NULL,
                severity TEXT NOT NULL,
                timestamp DATETIME NOT NULL,
                source_event TEXT,
                resolved BOOLEAN DEFAULT FALSE
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def start_tracking(self):
        """Start comprehensive real-time tracking"""
        self.tracking_active = True
        self.event_processor_active = True
        
        # Start all monitoring components
        self.market_streamer.start_streaming()
        self.blockchain_monitor.start_monitoring()
        self.governance_monitor.start_monitoring()
        
        # Start event processor
        self._start_event_processor()
        
        logging.info("Advanced real-time tracking system started")
    
    def stop_tracking(self):
        """Stop real-time tracking"""
        self.tracking_active = False
        self.event_processor_active = False
        
        # Stop all monitoring components
        self.market_streamer.stop_streaming()
        self.blockchain_monitor.stop_monitoring()
        self.governance_monitor.stop_monitoring()
        
        logging.info("Advanced real-time tracking system stopped")
    
    def _start_event_processor(self):
        """Start event processing thread"""
        def process_events():
            while self.event_processor_active:
                try:
                    # Process events from all sources
                    self._process_queue_events(self.market_streamer.data_queue)
                    self._process_queue_events(self.blockchain_monitor.event_queue)
                    self._process_queue_events(self.governance_monitor.event_queue)
                    
                    time.sleep(1)  # Process every second
                    
                except Exception as e:
                    logging.error(f"Error in event processor: {e}")
                    time.sleep(5)
        
        threading.Thread(target=process_events, daemon=True).start()
    
    def _process_queue_events(self, event_queue: queue.Queue):
        """Process events from a queue"""
        try:
            while not event_queue.empty():
                event = event_queue.get_nowait()
                self._process_single_event(event)
        except queue.Empty:
            pass
        except Exception as e:
            logging.error(f"Error processing queue events: {e}")
    
    def _process_single_event(self, event: RealTimeEvent):
        """Process a single event"""
        try:
            # Store event
            self._store_event(event)
            
            # Process through rule engine
            alerts = self.rule_engine.process_event(event)
            
            # Store and handle alerts
            for alert in alerts:
                self._store_alert(alert)
                self._handle_alert(alert)
            
            # Mark event as processed
            event.processed = True
            
        except Exception as e:
            logging.error(f"Error processing event {event.event_id}: {e}")
    
    def _store_event(self, event: RealTimeEvent):
        """Store event in database"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO events (event_id, event_type, source, timestamp, data, severity, processed)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                event.event_id,
                event.event_type,
                event.source,
                event.timestamp,
                json.dumps(event.data),
                event.severity,
                event.processed
            ))
            
            conn.commit()
            conn.close()
        except Exception as e:
            logging.error(f"Error storing event: {e}")
    
    def _store_alert(self, alert: Alert):
        """Store alert in database"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO alerts (alert_id, alert_type, title, message, severity, timestamp, source_event, resolved)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                alert.alert_id,
                alert.alert_type,
                alert.title,
                alert.message,
                alert.severity,
                alert.timestamp,
                alert.source_event,
                alert.resolved
            ))
            
            conn.commit()
            conn.close()
        except Exception as e:
            logging.error(f"Error storing alert: {e}")
    
    def _handle_alert(self, alert: Alert):
        """Handle an alert based on its severity and type"""
        try:
            if alert.severity == 'CRITICAL':
                # Immediate action required
                logging.critical(f"CRITICAL ALERT: {alert.title}")
                # Would trigger emergency notifications
            elif alert.severity == 'HIGH':
                # Urgent action required
                logging.error(f"HIGH PRIORITY ALERT: {alert.title}")
                # Would trigger high-priority notifications
            elif alert.severity == 'MEDIUM':
                # Standard alert handling
                logging.warning(f"ALERT: {alert.title}")
            else:
                # Low priority logging
                logging.info(f"Info: {alert.title}")
                
        except Exception as e:
            logging.error(f"Error handling alert {alert.alert_id}: {e}")
    
    def get_tracking_dashboard(self) -> Dict:
        """Get comprehensive tracking dashboard data"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # Get recent events
            events_df = pd.read_sql_query('''
                SELECT event_type, severity, COUNT(*) as count
                FROM events 
                WHERE timestamp > datetime('now', '-24 hours')
                GROUP BY event_type, severity
            ''', conn)
            
            # Get recent alerts
            alerts_df = pd.read_sql_query('''
                SELECT alert_type, severity, COUNT(*) as count
                FROM alerts 
                WHERE timestamp > datetime('now', '-24 hours')
                GROUP BY alert_type, severity
            ''', conn)
            
            # Get unresolved alerts
            unresolved_alerts_df = pd.read_sql_query('''
                SELECT * FROM alerts 
                WHERE resolved = FALSE
                ORDER BY timestamp DESC
                LIMIT 10
            ''', conn)
            
            conn.close()
            
            return {
                'system_status': {
                    'tracking_active': self.tracking_active,
                    'components': {
                        'market_streaming': self.market_streamer.streaming,
                        'blockchain_monitoring': self.blockchain_monitor.monitoring,
                        'governance_monitoring': self.governance_monitor.monitoring
                    }
                },
                'recent_events': events_df.to_dict('records'),
                'recent_alerts': alerts_df.to_dict('records'),
                'unresolved_alerts': unresolved_alerts_df.to_dict('records'),
                'total_events_24h': len(events_df),
                'total_alerts_24h': len(alerts_df),
                'critical_alerts': len(unresolved_alerts_df[unresolved_alerts_df['severity'] == 'CRITICAL'])
            }
            
        except Exception as e:
            logging.error(f"Error getting tracking dashboard: {e}")
            return {}
    
    def add_custom_rule(self, rule: MonitoringRule):
        """Add a custom monitoring rule"""
        self.rule_engine.rules.append(rule)
        logging.info(f"Custom rule added: {rule.rule_name}")
    
    def get_event_history(self, event_type: str = None, hours: int = 24) -> List[Dict]:
        """Get event history"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            if event_type:
                query = '''
                    SELECT * FROM events 
                    WHERE event_type = ? AND timestamp > datetime('now', '-{} hours')
                    ORDER BY timestamp DESC
                '''.format(hours)
                df = pd.read_sql_query(query, conn, params=[event_type])
            else:
                query = '''
                    SELECT * FROM events 
                    WHERE timestamp > datetime('now', '-{} hours')
                    ORDER BY timestamp DESC
                '''.format(hours)
                df = pd.read_sql_query(query, conn)
            
            conn.close()
            return df.to_dict('records')
            
        except Exception as e:
            logging.error(f"Error getting event history: {e}")
            return []